# cython: language_level=3
# cython: boundscheck=False
# cython: wraparound=False
# cython: cdivision=True
# cython: initializedcheck=False

"""
Advanced Polymorphic and Metamorphic Malware Detector
Cython-optimized for maximum performance
"""

import numpy as np
cimport numpy as cnp
from libc.math cimport log, exp, sqrt, fabs, tanh
from libc.stdlib cimport malloc, free
from libc.string cimport memcpy, memset
import cython
from cpython.bytes cimport PyBytes_AsString, PyBytes_Size

cnp.import_array()

ctypedef cnp.uint8_t BYTE_t
ctypedef cnp.float64_t DTYPE_t

@cython.boundscheck(False)
@cython.wraparound(False)
cdef class ByteSequenceAnalyzer:
    """Ultra-fast byte sequence analysis for polymorphic detection"""

    cdef unsigned int[:] ngram_hash
    cdef double[:] entropy_values
    cdef int window_size
    cdef int max_ngrams
    cdef double[:] pattern_scores

    def __init__(self, int window_size=8, int max_ngrams=65536):
        self.window_size = window_size
        self.max_ngrams = max_ngrams
        self.ngram_hash = np.zeros(max_ngrams, dtype=np.uint32)
        self.entropy_values = np.zeros(256, dtype=np.float64)
        self.pattern_scores = np.zeros(1000, dtype=np.float64)

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef double calculate_entropy(self, unsigned char* data, int length) nogil:
        """Calculate Shannon entropy of byte sequence"""
        cdef int i
        cdef unsigned int counts[256]
        cdef double entropy = 0.0
        cdef double probability

        # Reset counts
        for i in range(256):
            counts[i] = 0

        # Count byte frequencies
        for i in range(length):
            counts[data[i]] += 1

        # Calculate entropy
        for i in range(256):
            if counts[i] > 0:
                probability = <double>counts[i] / <double>length
                entropy -= probability * log(probability) / log(2.0)

        return entropy

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef unsigned int rolling_hash(self, unsigned char* data, int length, int window) nogil:
        """Compute rolling hash for n-gram detection"""
        cdef unsigned int hash_val = 0
        cdef int i
        cdef unsigned int prime = 31

        for i in range(min(window, length)):
            hash_val = hash_val * prime + data[i]

        return hash_val % self.max_ngrams

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef void extract_ngrams(self, unsigned char* data, int length) nogil:
        """Extract all n-grams and update hash table"""
        cdef int i
        cdef unsigned int hash_val

        # Reset hash table
        for i in range(self.max_ngrams):
            self.ngram_hash[i] = 0

        # Extract n-grams
        for i in range(length - self.window_size + 1):
            hash_val = self.rolling_hash(&data[i], length - i, self.window_size)
            self.ngram_hash[hash_val] += 1

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cpdef double[:] analyze_bytes(self, bytes data):
        """Complete byte sequence analysis"""
        cdef unsigned char* byte_data = <unsigned char*>PyBytes_AsString(data)
        cdef int length = PyBytes_Size(data)
        cdef double[:] features = np.zeros(10, dtype=np.float64)
        cdef int i, unique_ngrams = 0
        cdef double entropy

        # Feature 1: Overall entropy
        features[0] = self.calculate_entropy(byte_data, length)

        # Feature 2: Local entropy variance
        cdef double local_ent, ent_sum = 0.0, ent_sq_sum = 0.0
        cdef int blocks = min(length // 64, 100)
        for i in range(blocks):
            local_ent = self.calculate_entropy(&byte_data[i * 64], min(64, length - i * 64))
            ent_sum += local_ent
            ent_sq_sum += local_ent * local_ent

        if blocks > 1:
            features[1] = sqrt(ent_sq_sum / blocks - (ent_sum / blocks) ** 2)

        # Feature 3-6: N-gram analysis
        self.extract_ngrams(byte_data, length)
        for i in range(self.max_ngrams):
            if self.ngram_hash[i] > 0:
                unique_ngrams += 1

        features[2] = <double>unique_ngrams / <double>min(length, self.max_ngrams)

        # Feature 7: Byte distribution uniformity
        cdef unsigned int byte_counts[256]
        for i in range(256):
            byte_counts[i] = 0
        for i in range(length):
            byte_counts[byte_data[i]] += 1

        cdef double chi_square = 0.0
        cdef double expected = <double>length / 256.0
        for i in range(256):
            chi_square += ((byte_counts[i] - expected) ** 2) / (expected + 1e-10)
        features[3] = chi_square / 256.0

        # Feature 8-9: Compression ratio estimation
        cdef int zeros = 0, repetitions = 0
        for i in range(length):
            if byte_data[i] == 0:
                zeros += 1
            if i > 0 and byte_data[i] == byte_data[i-1]:
                repetitions += 1

        features[4] = <double>zeros / <double>length
        features[5] = <double>repetitions / <double>length

        return features

@cython.boundscheck(False)
@cython.wraparound(False)
cdef class OpCodeAnalyzer:
    """Analyze x86/x64 opcodes for metamorphic code detection"""

    cdef unsigned int[:] opcode_freq
    cdef double[:] instruction_patterns
    cdef int pattern_count

    def __init__(self):
        self.opcode_freq = np.zeros(256, dtype=np.uint32)
        self.instruction_patterns = np.zeros(500, dtype=np.float64)
        self.pattern_count = 0

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef bint is_suspicious_opcode(self, unsigned char opcode) nogil:
        """Detect suspicious opcodes commonly used in malware"""
        # Self-modifying code indicators
        if opcode in [0xEB, 0xE9, 0xE8]:  # JMP, CALL
            return True
        # Interrupt/syscall opcodes
        if opcode in [0xCC, 0xCD, 0x0F]:  # INT, SYSCALL
            return True
        # Stack manipulation
        if opcode in [0x50, 0x58, 0x68]:  # PUSH, POP
            return True
        return False

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef double detect_code_caves(self, unsigned char* data, int length) nogil:
        """Detect code caves (unused space in executables)"""
        cdef int i, cave_size = 0, max_cave = 0
        cdef int threshold = 16

        for i in range(length):
            if data[i] == 0 or data[i] == 0x90:  # NOP or NULL
                cave_size += 1
            else:
                if cave_size > max_cave:
                    max_cave = cave_size
                cave_size = 0

        return <double>max_cave / <double>length if length > 0 else 0.0

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef double detect_instruction_substitution(self, unsigned char* data, int length) nogil:
        """Detect instruction substitution patterns"""
        cdef int i
        cdef double substitution_score = 0.0
        cdef unsigned char byte_val

        # Look for functionally equivalent but different instruction sequences
        for i in range(length - 2):
            # XOR EAX, EAX vs MOV EAX, 0
            if data[i] == 0x31 and data[i+1] == 0xC0:  # XOR EAX, EAX
                substitution_score += 1.0
            elif data[i] == 0xB8 and data[i+1] == 0x00:  # MOV EAX, 0
                substitution_score += 1.0

            # ADD/SUB vs INC/DEC
            if data[i] == 0x40 or data[i] == 0x48:  # INC/DEC
                substitution_score += 0.5

        return substitution_score / <double>length

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cpdef double[:] analyze_opcodes(self, bytes data):
        """Complete opcode analysis"""
        cdef unsigned char* byte_data = <unsigned char*>PyBytes_AsString(data)
        cdef int length = PyBytes_Size(data)
        cdef double[:] features = np.zeros(15, dtype=np.float64)
        cdef int i, suspicious_count = 0

        # Reset frequency table
        for i in range(256):
            self.opcode_freq[i] = 0

        # Analyze opcodes
        for i in range(length):
            self.opcode_freq[byte_data[i]] += 1
            if self.is_suspicious_opcode(byte_data[i]):
                suspicious_count += 1

        # Feature extraction
        features[0] = <double>suspicious_count / <double>length

        # Opcode diversity
        cdef int unique_opcodes = 0
        for i in range(256):
            if self.opcode_freq[i] > 0:
                unique_opcodes += 1
        features[1] = <double>unique_opcodes / 256.0

        # Code cave detection
        features[2] = self.detect_code_caves(byte_data, length)

        # Instruction substitution patterns
        features[3] = self.detect_instruction_substitution(byte_data, length)

        # Jump/Call ratio
        cdef int jumps = self.opcode_freq[0xEB] + self.opcode_freq[0xE9]
        cdef int calls = self.opcode_freq[0xE8]
        features[4] = <double>(jumps + calls) / <double>length

        return features

@cython.boundscheck(False)
@cython.wraparound(False)
cdef class PolymorphicDetector:
    """Main polymorphic malware detection engine"""

    cdef ByteSequenceAnalyzer byte_analyzer
    cdef OpCodeAnalyzer opcode_analyzer
    cdef double[:] detection_thresholds
    cdef double[:] feature_weights

    def __init__(self):
        self.byte_analyzer = ByteSequenceAnalyzer(window_size=8)
        self.opcode_analyzer = OpCodeAnalyzer()
        self.detection_thresholds = np.array([
            7.0,   # Entropy threshold
            0.15,  # Polymorphism indicator
            0.10,  # Code cave threshold
            0.05,  # Substitution threshold
            0.20   # Obfuscation threshold
        ], dtype=np.float64)

        # Feature importance weights (learned from training)
        self.feature_weights = np.array([
            1.5,   # Entropy
            1.2,   # Variance
            1.8,   # N-gram uniqueness
            1.0,   # Chi-square
            0.8,   # Zero ratio
            0.9,   # Repetition
            2.0,   # Suspicious opcodes
            1.5,   # Opcode diversity
            2.5,   # Code caves
            2.0,   # Instruction substitution
            1.3    # Jump/call ratio
        ], dtype=np.float64)

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef double compute_polymorphism_score(self, double[:] byte_features, double[:] opcode_features) nogil:
        """Compute overall polymorphism score"""
        cdef double score = 0.0
        cdef int i

        # Weighted combination of features
        for i in range(min(6, len(byte_features))):
            score += byte_features[i] * self.feature_weights[i]

        for i in range(min(5, len(opcode_features))):
            score += opcode_features[i] * self.feature_weights[i + 6]

        return tanh(score / 10.0)  # Normalize to [0, 1]

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef bint detect_self_modification(self, unsigned char* data, int length) nogil:
        """Detect self-modifying code patterns"""
        cdef int i
        cdef int mod_indicators = 0

        for i in range(length - 4):
            # Look for write-to-code-section patterns
            if data[i] == 0xC7:  # MOV [mem], imm
                mod_indicators += 1
            # Look for dynamic code generation
            if data[i] == 0x0F and data[i+1] == 0x05:  # SYSCALL
                mod_indicators += 1

        return mod_indicators > (length // 1000)

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cpdef dict detect(self, bytes file_data):
        """Main detection method"""
        cdef double[:] byte_features = self.byte_analyzer.analyze_bytes(file_data)
        cdef double[:] opcode_features = self.opcode_analyzer.analyze_opcodes(file_data)
        cdef double polymorphism_score = self.compute_polymorphism_score(byte_features, opcode_features)

        cdef unsigned char* data = <unsigned char*>PyBytes_AsString(file_data)
        cdef int length = PyBytes_Size(file_data)
        cdef bint self_modifying = self.detect_self_modification(data, length)

        # Determine threat level
        cdef str threat_level = "CLEAN"
        cdef bint is_malicious = False

        if polymorphism_score > 0.8 or self_modifying:
            threat_level = "CRITICAL"
            is_malicious = True
        elif polymorphism_score > 0.6:
            threat_level = "HIGH"
            is_malicious = True
        elif polymorphism_score > 0.4:
            threat_level = "MEDIUM"
        elif polymorphism_score > 0.2:
            threat_level = "LOW"

        return {
            'is_malicious': is_malicious,
            'threat_level': threat_level,
            'polymorphism_score': float(polymorphism_score),
            'entropy': float(byte_features[0]),
            'code_cave_ratio': float(opcode_features[2]),
            'self_modifying': self_modifying,
            'byte_features': np.asarray(byte_features),
            'opcode_features': np.asarray(opcode_features)
        }

@cython.boundscheck(False)
@cython.wraparound(False)
cdef class MetamorphicDetector:
    """Advanced metamorphic malware detection using quantum-inspired analysis"""

    cdef double[:, :] instruction_graph
    cdef int max_nodes
    cdef double[:] centrality_scores

    def __init__(self, int max_nodes=1000):
        self.max_nodes = max_nodes
        self.instruction_graph = np.zeros((max_nodes, max_nodes), dtype=np.float64)
        self.centrality_scores = np.zeros(max_nodes, dtype=np.float64)

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef void build_control_flow_graph(self, unsigned char* data, int length) nogil:
        """Build control flow graph from bytecode"""
        cdef int i, j, current_node = 0, target_node
        cdef unsigned char opcode

        # Reset graph
        for i in range(self.max_nodes):
            for j in range(self.max_nodes):
                self.instruction_graph[i, j] = 0.0

        # Build graph from control flow
        for i in range(length - 1):
            opcode = data[i]

            # Connect sequential instructions
            if current_node < self.max_nodes - 1:
                self.instruction_graph[current_node, current_node + 1] = 1.0

            # Handle jumps
            if opcode == 0xEB or opcode == 0xE9:  # JMP
                if i + 2 < length:
                    target_node = (current_node + <int>data[i+1]) % self.max_nodes
                    self.instruction_graph[current_node, target_node] = 2.0

            current_node = (current_node + 1) % self.max_nodes
            if current_node >= self.max_nodes:
                break

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef double compute_graph_complexity(self) nogil:
        """Compute control flow graph complexity"""
        cdef int i, j
        cdef double complexity = 0.0
        cdef int edges = 0

        for i in range(self.max_nodes):
            for j in range(self.max_nodes):
                if self.instruction_graph[i, j] > 0.0:
                    edges += 1
                    complexity += self.instruction_graph[i, j]

        return complexity / (<double>edges + 1.0)

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cpdef dict detect_metamorphic(self, bytes file_data):
        """Detect metamorphic malware"""
        cdef unsigned char* data = <unsigned char*>PyBytes_AsString(file_data)
        cdef int length = PyBytes_Size(file_data)

        # Build and analyze control flow
        self.build_control_flow_graph(data, length)
        cdef double complexity = self.compute_graph_complexity()

        # Metamorphic indicators
        cdef bint is_metamorphic = complexity > 1.5

        return {
            'is_metamorphic': is_metamorphic,
            'cfg_complexity': float(complexity),
            'confidence': float(tanh(complexity))
        }
